{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du dataset `imdb_wiki_corpus.csv`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook permet de créer un corpus pour le fine-tuning d'un modèle pour la summarization. Il est créé à partir des corpus suivants : \n",
    "\n",
    "- des plots détaillés de Wikipédia : WikiPlots : https://github.com/markriedl/WikiPlots\n",
    "- des synopsis courts de IMDB : Movie Synopsis Dataset : https://www.kaggle.com/datasets/linggarmaretva/movie-synopsis-dataset\n",
    "\n",
    "A chaque plot détaillé, on lui associe son synopsis court IMDB en considérant que c'est son résumé. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fichiers avec les données\n",
    "imdb_synopsis_file = \"../movie_synopsis.csv\"\n",
    "wiki_plots_file = \"../plots/plots\"\n",
    "wiki_titles_file = \"../plots/titles\"\n",
    "\n",
    "# Lecture du fichier avec les synopsis IMDB\n",
    "with open(imdb_synopsis_file, \"r\", encoding=\"utf-8\") as csvfile:\n",
    "    csv_reader = csv.DictReader(csvfile)\n",
    "    \n",
    "    # Création d'un dictionnaire {title: synopsis_IMDB}\n",
    "    imdb_data = {row[\"title\"].lower(): row[\"synopsis\"] for row in csv_reader}\n",
    "    \n",
    "# Lecture du fichier avec les plots détaillés Wikipédia\n",
    "with open(wiki_plots_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    l = f.readline()\n",
    "    \n",
    "    plots = []\n",
    "    temp_plot = [] # Un plot peut s'étaler sur plusieurs lignes\n",
    "    \n",
    "    while l:\n",
    "        if l == \"<EOS>\\n\": # Fin du plot\n",
    "            plots.append(\"\".join(temp_plot)) # Transformation de la liste en string\n",
    "            temp_plot = [] # On vide la liste tampon\n",
    "        else:\n",
    "            temp_plot.append(l.strip())\n",
    "    \n",
    "        l = f.readline()\n",
    "        \n",
    "# Lecture du fichier avec les titres correspondants aux plots de Wikipédia\n",
    "with open(wiki_titles_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki_titles = []\n",
    "    l = f.readline()\n",
    "    while l :\n",
    "        title = re.sub(r\"\\((\\w+|\\s|\\d+)+\\)\", \"\", l) # Suppression des infos entre parenthèses (ex : \"(movie)\", \"(1998)\", ...)\n",
    "        wiki_titles.append(title.lower().strip()) # Tout en minuscules et suppression des trailing spaces\n",
    "        l = f.readline()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En tout, on a 112936 oeuvres.\n"
     ]
    }
   ],
   "source": [
    "# Liste de dictionnaires : un dico = une oeuvre = {\"document\": \"long plot wikipédia\", \"summary\": \"court synopsis IMDB\"}\n",
    "oeuvres = [{\"document\": plot, \"summary\": imdb_data.get(title, \"\")} for plot, title in zip(plots, wiki_titles)]\n",
    "\n",
    "print(f\"En tout, on a {len(oeuvres)} oeuvres.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9807 des 112936 plots Wikipédia ont un synopsis IMDB\n"
     ]
    }
   ],
   "source": [
    "# Suppression des oeuvres pour lesquelles on a pas le synopsis IMDB\n",
    "oeuvres_no_empty = [oeuvre for oeuvre in oeuvres if oeuvre[\"summary\"]!=\"\"]\n",
    "\n",
    "print(f\"{len(oeuvres_no_empty)} des {len(oeuvres)} plots Wikipédia ont un synopsis IMDB\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : Il est normal que notre dataset de plot wikipédia-synopsis IMDB soit plus long que celui de IMDB car il peut y avoir plusieurs fois la même oeuvre dans les plots alors que dans les synopsis, il y a un synopsis par oeuvre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset(data, path):\n",
    "    \"\"\"Ecrire le dataset dans un fichier CSV\"\"\"\n",
    "    columns = data[0].keys() # Nom des colonnes (\"document\", \"summary\")\n",
    "    with open(path, \"w\", encoding=\"utf-8\", newline='') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, columns)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data)\n",
    "        \n",
    "write_dataset(oeuvres_no_empty, \"../Data/imdb_wiki_corpus.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvInterfacesWeb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
